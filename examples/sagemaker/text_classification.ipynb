{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "<!--- @wandbcode{sagemaker-hf} -->\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/sagemaker/text_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Sagemaker & Weights & Biases\n",
    "\n",
    "This notebook will demonstrate how to:\n",
    "- log the datasets to W&B Tables for EDA\n",
    "- train on the [`banking77`](https://huggingface.co/datasets/banking77) dataset\n",
    "- log experiment results to Weights & Biases\n",
    "- log the validation predictions to W&B Tables for model evaluation\n",
    "- save the raw dataset, processed dtaset and model weights to W&B Artifacts\n",
    "\n",
    "Note, this notebook should be run in a SageMaker notebook instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/Za9P1sr.png\" width=\"400\" alt=\"Weights & Biases\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker is a comprehensive machine learning service. It is a tool that helps data scientists and developers to prepare, build, train, and deploy high-quality machine learning (ML) models by providing a rich set of orchestration tools and features.\n",
    "\n",
    "## Credit\n",
    "\n",
    "This notebook is based on the Hugging Face & AWS SageMaker examples that can be [found here](https://huggingface.co/docs/sagemaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq wandb --upgrade\n",
    "!pip install -qq \"sagemaker>=2.48.0\" \"transformers>=4.6.1\" \"datasets[s3]>=1.6.2\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights & Biases Setup for AWS SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmorgan\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **only** additional piece of setup needed to use W&B with SageMaker is to make your W&B API key available to SageMaker. In this case we save it to a file in the same directory as our training script. This will be named `secrets.env` and W&B will then use this to authenticate on each of the instances that SageMaker spins up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sagemaker_auth(path=\"scripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Dataset for Exporatory Analysis in W&B Tables\n",
    "\n",
    "Here we log the `train` and `eval` datasets to separtate W&B Tables. After this is run, we can explore these tables in the W&B UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">log_dataset_to_table</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/morgan/hf-sagemaker\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/morgan/hf-sagemaker/runs/1katv7vs\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker/runs/1katv7vs</a><br/>\n",
       "                Run data is saved locally in <code>/home/ec2-user/SageMaker/wandb/run-20210816_101529-1katv7vs</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset banking77 (/home/ec2-user/.cache/huggingface/datasets/banking77/default/1.1.0/17ffc2ed47c2ed928bee64127ff1dbc97204cb974c2f980becae7c864007aed9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 486<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c85f0c5030f468397449a92a64f0948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 2.20MB of 2.20MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ec2-user/SageMaker/wandb/run-20210816_101529-1katv7vs/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ec2-user/SageMaker/wandb/run-20210816_101529-1katv7vs/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>11</td></tr><tr><td>_timestamp</td><td>1629108940</td></tr><tr><td>_step</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁█</td></tr><tr><td>_timestamp</td><td>▁█</td></tr><tr><td>_step</td><td>▁█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">log_dataset_to_table</strong>: <a href=\"https://wandb.ai/morgan/hf-sagemaker/runs/1katv7vs\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker/runs/1katv7vs</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(name='log_dataset_to_table', project='hf-sagemaker', job_type='TableLogging')\n",
    "\n",
    "raw_dataset = load_dataset('banking77')\n",
    "label_list = raw_dataset['train'].features[\"label\"].names\n",
    "\n",
    "# ✍️ Log the training and eval datasets as a Weights & Biases Tables to Artifacts ✍️\n",
    "for split in ['train','test']:\n",
    "    \n",
    "    ds = raw_dataset[split]\n",
    "    \n",
    "    # Create W&B Table\n",
    "    dataset_table = wandb.Table(columns=['id', 'label_id', 'label', 'text'])\n",
    "\n",
    "    # Ensure different row ids when logging train and eval data\n",
    "    if split == 'test':\n",
    "        idx_step = len(raw_dataset['train'])\n",
    "        nm = 'eval'\n",
    "    else:\n",
    "        idx_step = 0\n",
    "        nm = 'train'\n",
    "\n",
    "    # Add each row of data to the table\n",
    "    for index in range(len(ds)):\n",
    "        idx = index + idx_step\n",
    "        lbl = ds[index]['label']\n",
    "        row = [idx, lbl, label_list[lbl], ds[index]['text']]\n",
    "        dataset_table.add_data(*row)\n",
    "\n",
    "    wandb.log({f'{nm} table': dataset_table})\n",
    "    \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with SageMaker and W&B\n",
    "\n",
    "### SageMaker Role\n",
    "\n",
    "First we need to get our SageMaker role permissions. If you are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker. You can find [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::618469898284:role/jeff-sagemaker\n",
      "sagemaker bucket: sagemaker-us-east-2-618469898284\n",
      "sagemaker session region: us-east-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Estimator and start a training job\n",
    "Here we will use the `HuggingFace` estimator from SageMaker, which includes an image of the main libraries necessary when training Hugging Face models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "model = 'distilbert-base-uncased'\n",
    "warmup_steps = 100\n",
    "lr = 1e-4\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'output_dir': 'tmp',\n",
    "    'overwrite_output_dir': True,\n",
    "    'model_name_or_path': model,\n",
    "    'dataset_name': 'banking77',\n",
    "    'do_train': True,\n",
    "    'per_device_train_batch_size': 16,\n",
    "    'per_device_eval_batch_size': 16,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'learning_rate': lr,\n",
    "    'warmup_steps': warmup_steps,\n",
    "    'fp16': True,\n",
    "    'logging_steps': 10,\n",
    "    'max_steps': 1200,\n",
    "    'eval_steps': 100,\n",
    "    'evaluation_strategy' : 'steps',\n",
    "    'save_steps': 600,\n",
    "    'save_total_limit' : 2,\n",
    "    'load_best_model_at_end': True,\n",
    "    'metric_for_best_model': 'accuracy',\n",
    "    'report_to': 'wandb',    # ✍️\n",
    "    }\n",
    "\n",
    "hyperparameters['run_name'] = f\"{model}_{lr}_{warmup_steps}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='run_text_classification.py',\n",
    "                            source_dir='./scripts',\n",
    "                            instance_type= 'ml.p3.2xlarge', \n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            transformers_version='4.6',\n",
    "                            pytorch_version='1.7',\n",
    "                            py_version='py36',\n",
    "                            hyperparameters = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning with SageMaker and Weights & Biases\n",
    "\n",
    "We can alsp use SageMaker's `HyperparameterTuner` to run hyperparameter search and log the results to Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_jobs=50\n",
    "max_parallel_jobs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'banking77_artifacts'  # Pre-tokenized dataset that will be downloaded from W&B Artifacts\n",
    "model = 'roberta-large'\n",
    "warmup_steps = None\n",
    "lr = 1e-5\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'output_dir': 'tmp',\n",
    "    'overwrite_output_dir': True,\n",
    "    'model_name_or_path': model,\n",
    "    'dataset_name': dataset_name,\n",
    "    'do_train': True,\n",
    "    'per_device_train_batch_size': 4,\n",
    "    'per_device_eval_batch_size': 4,\n",
    "    'gradient_accumulation_steps': 8,\n",
    "    'learning_rate': lr,\n",
    "    'warmup_steps': warmup_steps,\n",
    "    'fp16': True,\n",
    "    'logging_steps': 10,\n",
    "    'max_steps': 1200,\n",
    "    'evaluation_strategy' : 'steps',\n",
    "    'eval_steps': 100,\n",
    "    'save_strategy': \"steps\", # \"no\"\n",
    "    'save_steps': 600,\n",
    "    'save_total_limit' : 1,\n",
    "    'load_best_model_at_end': True,\n",
    "    'metric_for_best_model': 'accuracy',\n",
    "    'report_to': 'wandb',    # ✍️\n",
    "    'run_name': 'hpt'  # will set run name \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='run_text_classification.py',\n",
    "    source_dir='./scripts',\n",
    "    instance_type= 'ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    transformers_version='4.6',\n",
    "    pytorch_version='1.7',\n",
    "    py_version='py36',\n",
    "    hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'learning_rate': ContinuousParameter(1e-5, 1e-4),\n",
    "    'warmup_steps': IntegerParameter(48, 320),\n",
    "    'model_name_or_path': CategoricalParameter([\"google/electra-large-discriminator\",\n",
    "                                                \"roberta-large\", \n",
    "                                                \"albert-large-v2\",\n",
    "                                               ])\n",
    "}\n",
    "\n",
    "objective_metric_name = 'eval_accuracy'\n",
    "objective_type = 'Maximize'\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"train_runtime\", \"Regex\": \"train_runtime.*=\\D*(.*?)\"},\n",
    "    {\"Name\": \"eval_accuracy\", \"Regex\": \"eval_accuracy.*=\\D*(.*?)\"},\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"eval_loss.*=\\D*(.*?)\"},\n",
    "]\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    huggingface_estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=max_jobs,\n",
    "    max_parallel_jobs=max_parallel_jobs,\n",
    "    objective_type=objective_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Versioning with W&B Artifacts\n",
    "\n",
    "Weights and Biases Artifacts enable you to log end-to-end training pipelines to ensure your experiments are always reproducible.\n",
    "\n",
    "Data privacy is critical to Weights & Biases and so we support the creation of Artifacts from reference locations such as your own private cloud such as AWS S3 or Google Cloud Storage. Local, on-premises of W&B are also available upon request.\n",
    "\n",
    "By default, W&B stores artifact files in a private Google Cloud Storage bucket located in the United States. All files are encrypted at rest and in transit. For sensitive files, we recommend a private W&B installation or the use of reference artifacts.\n",
    "\n",
    "### Artifacts - Log Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'banking77'\n",
    "dataset_path = Path('data')\n",
    "raw_dataset_path = dataset_path/f'{dataset_name}_raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log to W&B Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">log_raw_dataset</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/morgan/hf-sagemaker\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/morgan/hf-sagemaker/runs/p231x1cq\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker/runs/p231x1cq</a><br/>\n",
       "                Run data is saved locally in <code>/home/ec2-user/SageMaker/wandb/run-20210815_120758-p231x1cq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset banking77 (/home/ec2-user/.cache/huggingface/datasets/banking77/default/1.1.0/17ffc2ed47c2ed928bee64127ff1dbc97204cb974c2f980becae7c864007aed9)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/banking77_raw)... Done. 0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f85ca81dc88>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='hf-sagemaker', name='log_raw_dataset', job_type='dataset-logging')\n",
    "\n",
    "# Download data and save to disk\n",
    "raw_datasets = load_dataset(dataset_name)\n",
    "raw_datasets.save_to_disk(raw_dataset_path)\n",
    "\n",
    "# Upload data to W&B Artifacts\n",
    "dataset_artifact = wandb.Artifact(f'{dataset_name}_raw', type='raw_dataset')\n",
    "dataset_artifact.add_dir(raw_dataset_path)\n",
    "wandb.log_artifact(dataset_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifacts - Log Train/Eval Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our train/eval paths\n",
    "train_dataset_path = dataset_path/f'{dataset_name}_train'\n",
    "eval_dataset_path = dataset_path/f'{dataset_name}_eval'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log to W&B Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">log_train_eval_split</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/morgan/hf-sagemaker\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/morgan/hf-sagemaker/runs/19ds3ai1\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker/runs/19ds3ai1</a><br/>\n",
       "                Run data is saved locally in <code>/home/ec2-user/SageMaker/wandb/run-20210815_120929-19ds3ai1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/banking77_train)... Done. 0.1s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/banking77_eval)... Done. 0.1s\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project='hf-sagemaker', name='log_train_eval_split', job_type='train-eval-split')\n",
    "\n",
    "# Download the raw dataset from W&B Artifacts\n",
    "artifact = wandb.use_artifact('morgan/hf-sagemaker/banking77_raw:v0', type='raw_dataset')\n",
    "artifact_dir = artifact.download(raw_dataset_path)\n",
    "\n",
    "# Load the raw dataset into a Hugging Face Datasets object\n",
    "raw_datasets = load_from_disk(artifact_dir)\n",
    "\n",
    "# Log the train and eval datasets as separate objects\n",
    "for split in ['train', 'test']:\n",
    "    ds = raw_datasets[split]\n",
    "    \n",
    "    if split == 'test':\n",
    "        split = 'eval'\n",
    "        \n",
    "    nm = f'{dataset_name}_{split}'    \n",
    "    \n",
    "    # Save the Hugging Face Datasets object to disk\n",
    "    ds.save_to_disk(dataset_path/nm)\n",
    "\n",
    "    # Upload the train or eval split to W&B Artifacts\n",
    "    artifact = wandb.Artifact(nm, type=f'{split}_dataset')\n",
    "    artifact.add_dir(dataset_path/nm)\n",
    "    wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27274<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1050a8246b5d4313ad34aca9113b6fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.88MB of 0.88MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ec2-user/SageMaker/wandb/run-20210815_120929-19ds3ai1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ec2-user/SageMaker/wandb/run-20210815_120929-19ds3ai1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">log_train_eval_split</strong>: <a href=\"https://wandb.ai/morgan/hf-sagemaker/runs/19ds3ai1\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker/runs/19ds3ai1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifacts - Dataset Preprocessing: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    result = tokenizer(examples['text'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if \"label\" in examples:\n",
    "        result[\"label\"] = examples[\"label\"]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models we'll be using\n",
    "models = [\"google/electra-large-discriminator\", \"roberta-large\", \"albert-large-v2\"]\n",
    "padding = \"max_length\"    \n",
    "max_seq_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">tokenization</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/morgan/hf-sagemaker\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/morgan/hf-sagemaker/runs/hzeiop8w\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker/runs/hzeiop8w</a><br/>\n",
       "                Run data is saved locally in <code>/home/ec2-user/SageMaker/wandb/run-20210815_124944-hzeiop8w</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53930bec24cf414086ce2b1991f73f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/banking77_train/banking77_train_electra-large-discriminator_tokenized)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_tokenized_dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae7d524be50478cbb75aa745d26927a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/banking77_train/banking77_train_roberta-large_tokenized)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_tokenized_dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396626cb517d4275827b9c55e9de8ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/banking77_train/banking77_train_albert-large-v2_tokenized)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_tokenized_dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bfe9c676924a0db3558cb8bd6c242d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/banking77_eval/banking77_eval_electra-large-discriminator_tokenized)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval_tokenized_dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ec97fa5a564e5c867f3661aa416d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/banking77_eval/banking77_eval_roberta-large_tokenized)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval_tokenized_dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c872d066068946409b7396680df6bf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/banking77_eval/banking77_eval_albert-large-v2_tokenized)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eval_tokenized_dataset\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "wandb.init(project='hf-sagemaker', name='tokenization', job_type='train-eval-tokenization')\n",
    "\n",
    "for split in ['train', 'eval']:\n",
    "    # Define our train/eval paths\n",
    "    ds_path = dataset_path/f'{dataset_name}_{split}'\n",
    "    \n",
    "    # Download the raw dataset from W&B Artifacts and load to HF Datasets object\n",
    "    artifact = wandb.use_artifact(f'morgan/hf-sagemaker/banking77_{split}:v0', type=f'{split}_dataset')\n",
    "    artifact_dir = artifact.download(ds_path)\n",
    "    dataset = load_from_disk(artifact_dir)\n",
    "    \n",
    "    for model_name in models:\n",
    "        nm = f\"{split}_{model_name.split('/')[-1]}_tokenized\"\n",
    "        pth = ds_path/f'{dataset_name}_{nm}'\n",
    "        \n",
    "        # Get tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "        max_seq_length = min(max_seq_length, tokenizer.model_max_length)\n",
    "\n",
    "        # Do tokenization\n",
    "        tok_dataset = dataset.map(preprocess_function, batched=True)\n",
    "        \n",
    "        # Save the Hugging Face Datasets object to disk\n",
    "        tok_dataset.save_to_disk(pth)\n",
    "\n",
    "        # Upload the train or eval split to W&B Artifacts\n",
    "        artifact = wandb.Artifact(nm, type=f'{split}_tokenized_dataset')\n",
    "        artifact.add_dir(pth)\n",
    "        wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5008<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982b62d782ba4c928f87658afb36d5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 111.67MB of 111.67MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ec2-user/SageMaker/wandb/run-20210815_124944-hzeiop8w/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ec2-user/SageMaker/wandb/run-20210815_124944-hzeiop8w/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">tokenization</strong>: <a href=\"https://wandb.ai/morgan/hf-sagemaker/runs/hzeiop8w\" target=\"_blank\">https://wandb.ai/morgan/hf-sagemaker/runs/hzeiop8w</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceLimitExceeded",
     "evalue": "An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'ml.p3.2xlarge for training job usage' is 2 Instances, with current utilization of 2 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dabcdca77f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                 hyperparameters = hyperparameters)\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mhuggingface_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \"\"\"\n\u001b[1;32m   1454\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m: An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'ml.p3.2xlarge for training job usage' is 2 Instances, with current utilization of 2 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit."
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "for i in range(12):\n",
    "    \n",
    "    # hyperparameters, which are passed into the training job\n",
    "    hyperparameters={\n",
    "        'output_dir': 'tmp',\n",
    "        'overwrite_output_dir': True,\n",
    "        'model_name_or_path': 'albert-large-v2', #'distilbert-base-uncased',  # microsoft/deberta-base , roberta-base\n",
    "        'dataset_name': 'banking77',\n",
    "        'do_train': True,\n",
    "        'per_device_train_batch_size': 16,\n",
    "        'per_device_eval_batch_size': 16,\n",
    "        'gradient_accumulation_steps': 4,\n",
    "        'learning_rate': 1e-4,\n",
    "        'warmup_steps': 100,\n",
    "        'fp16': True,\n",
    "        'logging_steps': 10,\n",
    "        'max_steps': 1200,\n",
    "        'eval_steps': 100,\n",
    "        'save_steps': 2000,\n",
    "        'save_total_limit' : 1,\n",
    "        'evaluation_strategy' : 'steps',\n",
    "        'load_best_model_at_end': True,\n",
    "        'metric_for_best_model': 'accuracy',\n",
    "        'report_to': 'wandb',    # ✍️\n",
    "    }\n",
    "    \n",
    "#     if i == 1: \n",
    "#         hyperparameters['model_name_or_path'] = \"roberta-large\"\n",
    "#     if i == 2: \n",
    "#         hyperparameters['model_name_or_path'] = \"roberta-base\"        \n",
    "    if i == 0: \n",
    "        hyperparameters['learning_rate'] = 3e-4\n",
    "    elif i == 1: \n",
    "        hyperparameters['model_name_or_path'] = \"roberta-base\"\n",
    "        hyperparameters['learning_rate'] = 3e-4\n",
    "    elif i == 2: \n",
    "        hyperparameters['model_name_or_path'] = \"roberta-large\"\n",
    "        hyperparameters['learning_rate'] = 3e-4\n",
    "    elif i == 3: \n",
    "        hyperparameters['learning_rate'] = 3e-5\n",
    "    elif i == 4: \n",
    "        hyperparameters['model_name_or_path'] = \"roberta-base\"\n",
    "        hyperparameters['learning_rate'] = 3e-5\n",
    "    elif i == 5: \n",
    "        hyperparameters['model_name_or_path'] = \"roberta-large\"\n",
    "        hyperparameters['learning_rate'] = 3e-5\n",
    "    elif i == 6: \n",
    "        hyperparameters['warmup_steps'] = None\n",
    "    elif i == 7: \n",
    "        hyperparameters['warmup_steps'] = None\n",
    "        hyperparameters['model_name_or_path'] = \"roberta-base\"\n",
    "    elif i == 8: \n",
    "        hyperparameters['warmup_steps'] = None\n",
    "        hyperparameters['model_name_or_path'] = \"roberta-large\"\n",
    "\n",
    "    hyperparameters['run_name'] = hyperparameters['model_name_or_path']    # ✍️'\n",
    "        \n",
    "    huggingface_estimator = HuggingFace(entry_point='run_text_classification.py',\n",
    "                                source_dir='./scripts',\n",
    "                                instance_type= 'ml.p3.2xlarge', #'ml.p3.8xlarge', #'ml.p3.2xlarge', ##'g4dn.12xlarge',\n",
    "                                instance_count=1,\n",
    "                                role=role,\n",
    "                                transformers_version='4.6',\n",
    "                                pytorch_version='1.7',\n",
    "                                py_version='py36',\n",
    "                                hyperparameters = hyperparameters)\n",
    "\n",
    "    huggingface_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W&B Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'output_dir': 'tmp',\n",
    "    'model_name_or_path': 'distilbert-base-uncased',  # microsoft/deberta-base , roberta-base\n",
    "    'dataset_name': 'banking77',\n",
    "    'do_train': True,\n",
    "    'do_eval': True,\n",
    "    'per_device_train_batch_size': 16,\n",
    "    'per_device_eval_batch_size': 16,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'learning_rate': 1e-4,\n",
    "    'warmup_steps': 100,\n",
    "    'fp16': True,\n",
    "    'logging_steps': 10,\n",
    "    'max_steps': 1200,\n",
    "    'eval_steps': 100,\n",
    "    'save_steps': 10000,\n",
    "    'evaluation_strategy' : 'steps',\n",
    "    'report_to': 'wandb',    # ✍️\n",
    "}\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='run_text_cls_sweep.py',\n",
    "    source_dir='./scripts',\n",
    "    instance_type= 'ml.p3.2xlarge', #'ml.p3.8xlarge', #'g4dn.12xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    transformers_version='4.6',\n",
    "    pytorch_version='1.7',\n",
    "    py_version='py36',\n",
    "    hyperparameters = hyperparameters\n",
    ")\n",
    "\n",
    "huggingface_estimator.fit(wait=False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
