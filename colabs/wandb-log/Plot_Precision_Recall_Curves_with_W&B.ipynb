{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Plot_Precision_Recall_Curves_with_W%26B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Glsegn-TCUZ3"
   },
   "source": [
    "# Plot Precision-Recall Curves with W&B\n",
    "\n",
    "How to log [Precision-Recall curves](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve) with [Vega](https://vega.github.io/vega/docs/) in [Weights & Biases](https://www.wandb.com).\n",
    "\n",
    "## Method: wandb.plot.pr_curve()\n",
    "\n",
    "- More info and customization details: [Plot Precision Recall Curves](https://wandb.ai/wandb/plots/reports/Plot-Precision-Recall-Curves--VmlldzoyNjk1ODY)\n",
    "- More examples in this W&B project: [Custom Charts](https://app.wandb.ai/demo-team/custom-charts).\n",
    "\n",
    "These are simple cases to explain the basics—you can build much more sophisticated custom charts with our powerful new query editor.\n",
    "\n",
    "This Colab explores a transfer learning problem: finetuning InceptionV3 with ImageNet weights to identify 10 types of living things (birds, plants, insects, etc) from 10K photos from [iNaturalist 2017](https://github.com/visipedia/inat_comp).\n",
    "\n",
    "![roc_and_pr](https://i.imgur.com/CqGXSzj.png)\n",
    "\n",
    "Note: Hyperparameters like number of epochs and training dataset size are set to minimum values here for demo efficiency. On the full training data, the model should get to the low 80s in validation accuracy within an epoch or so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Pn_0J6sxMjN"
   },
   "source": [
    "## Setup: Download data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKvmHmtOxqvK"
   },
   "source": [
    "Note: **this stage might take a few minutes (~3.6GB of data)**. If you end up needing to rerun this cell, comment out the first capture line (change ```%%capture``` to ```#%%capture``` ) so you can respond to the prompt about re-downloading the dataset (and see the progress bar).\n",
    "\n",
    "Download sample data: 10,000 training images and 2,000 validation images from the [iNaturalist dataset](https://github.com/visipedia/inat_comp), evenly distributed across 10 classes of living things like birds, insects, plants, and mammals (names given in Latin—so Aves, Insecta, Plantae, etc :). We will fine-tune a convolutional neural network already trained on ImageNet on this task: given a photo of a living thing, correctly classify it into one of the 10 classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnz9rnRFxqG0"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!curl -SL https://storage.googleapis.com/wandb_datasets/nature_12K.zip > nature_12K.zip\n",
    "!unzip nature_12K.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRHxDDkzlT-8"
   },
   "source": [
    "# Install dependencies\n",
    "\n",
    "Install tensorflow and wandb; log in to wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzxVDwuXlbwR",
    "outputId": "41d07b0b-b5c2-4a33-87fe-0291824706da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.8MB 7.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 163kB 28.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 133kB 27.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 102kB 10.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 102kB 11.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
      "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow -qqq\n",
    "!pip3 install wandb -qqq\n",
    "import wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4Jv8vrvx1S_"
   },
   "source": [
    "# Training code\n",
    "\n",
    "Feel free to try different values for \"NUM_TRAIN\" and \"NUM_EPOCHS\" below so you can see a variety of PR curves (generally better ones with more training examples/longer training time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7097i45lx8sf"
   },
   "outputs": [],
   "source": [
    "# this determines the name of your wandb project, where all your\n",
    "# runs will be loggeed\n",
    "PROJECT_NAME = \"custom_pr_curve\"\n",
    "\n",
    "# EXPERIMENT CONFIG\n",
    "#---------------------------\n",
    "# try changing the number of training examples\n",
    "# to generate a range of different PR curves\n",
    "NUM_TRAIN = 100 # try 500, 1000, 2000, or max 10000\n",
    "NUM_EPOCHS = 1 # try 3, 5, or as many as you like\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# local paths to data\n",
    "train_data = \"inaturalist_12K/train\"\n",
    "val_data = \"inaturalist_12K/val\"\n",
    "\n",
    "# experiment configuration saved to W&B\n",
    "config_defaults = {\n",
    "  # number of images used to train--set low for demo training speed\n",
    "  # you can set this up to 10000 for the full dataset\n",
    "  # GOOD CONFIG TO TRY: 100, 500, 1000, 2000\n",
    "  \"num_train\" : NUM_TRAIN, # up to 10000,\n",
    "  # number of images used to validate--set low for demo training speed\n",
    "  # you can set this up to 2000 for the full dataset\n",
    "  \"num_val\" : 500, #2000,\n",
    "  \"num_classes\" : 10,\n",
    "  \"fc_size\" : 1024,\n",
    "\n",
    "  # inceptionV3 settings\n",
    "  \"img_width\" : 299,\n",
    "  \"img_height\": 299,\n",
    "  \"batch_size\" : 32,\n",
    "\n",
    "  # number of epochs--set low for demo training speed\n",
    "  # you can set this up to 5, 10, or more for better results\n",
    "  # GOOD CONFIG TO TRY: 3, 5, 10\n",
    "  \"pretrain_epochs\" : NUM_EPOCHS, #5,\n",
    "  # number of validation data batches to use when computing metrics\n",
    "  # at the end of each epoch\n",
    "  \"num_log_batches\": 15\n",
    "}\n",
    "\n",
    "def build_model(fc_size, num_classes):\n",
    "  \"\"\"Load InceptionV3 with ImageNet weights, freeze it,\n",
    "  and attach a finetuning top for this classification task\"\"\"\n",
    "  # load InceptionV3 as base\n",
    "  base = InceptionV3(weights=\"imagenet\", include_top=\"False\")\n",
    "  # freeze base layers\n",
    "  for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "  x = base.get_layer('mixed10').output \n",
    "\n",
    "  # attach a fine-tuning layer\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(fc_size, activation='relu')(x)\n",
    "  guesses = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=base.input, outputs=guesses)\n",
    "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def pretrain():\n",
    "  \"\"\" Main training loop. This is called pretrain because it freezes\n",
    "  the InceptionV3 layers of the model and only trains the new top layers\n",
    "  on the new data.   subsequent training phase would unfreeze all the layers\n",
    "  and finetune the whole model on the new data\"\"\" \n",
    "  # track this experiment with wandb: all runs will be sent\n",
    "  # to the given project name\n",
    "  wandb.init(project=PROJECT_NAME, config=config_defaults)\n",
    "  cfg = wandb.config\n",
    "\n",
    "  # create train and validation data generators\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True)\n",
    "  val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(\n",
    "    train_data,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "  val_generator = val_datagen.flow_from_directory(\n",
    "    val_data,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "  # instantiate model and callbacks\n",
    "  model = build_model(cfg.fc_size, cfg.num_classes)\n",
    "  callbacks = [WandbCallback(), PRMetrics(val_generator, num_log_batches=15)]\n",
    "\n",
    "  # train!\n",
    "  model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = cfg.num_train // cfg.batch_size,\n",
    "    epochs=cfg.pretrain_epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks = callbacks,\n",
    "    validation_steps=cfg.num_val // cfg.batch_size)\n",
    "\n",
    "  wandb.run.finish()\n",
    "  \n",
    "class PRMetrics(Callback):\n",
    "  \"\"\" Custom callback to compute per-class PR & ROC curves\n",
    "  at the end of each training epoch\"\"\"\n",
    "  def __init__(self, generator=None, num_log_batches=1):\n",
    "    self.generator = generator\n",
    "    self.num_batches = num_log_batches\n",
    "    # store full names of classes\n",
    "    self.class_names = { v: k for k, v in generator.class_indices.items() }\n",
    "    self.flat_class_names = [k for k, v in generator.class_indices.items()]\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    # collect validation data and ground truth labels from generator\n",
    "    val_data, val_labels = zip(*(self.generator[i] for i in range(self.num_batches)))\n",
    "    val_data, val_labels = np.vstack(val_data), np.vstack(val_labels)\n",
    "\n",
    "    # use the trained model to generate predictions for the given number\n",
    "    # of validation data batches (num_batches)\n",
    "    val_predictions = self.model.predict(val_data)\n",
    "    ground_truth_class_ids = val_labels.argmax(axis=1)\n",
    "\n",
    "    # Log precision-recall curve\n",
    "    # the key \"pr_curve\" is the id of the plot--do not change\n",
    "    # this if you want subsequent runs to show up on the same plot\n",
    "    wandb.log({\"pr_curve\" : wandb.plot.pr_curve(ground_truth_class_ids, \n",
    "                                                val_predictions,\n",
    "                                                labels=self.flat_class_names)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891,
     "referenced_widgets": [
      "f402c6403630417388a23b752072183c",
      "89b63a2f8c894190b1d938940eba9342",
      "6b96a9dc6abf4478a83884c9672e8075",
      "92917c9a955946d3be240b4fac968c31",
      "8788e67cc403481dbbdf5303877f4b6b",
      "dd80cdc597ad4c8ca743b28f3b470c39",
      "2eb2de95870b4ffdb3ec3a14d9235e0e",
      "2b9e6c5624514b04ad75d6a7563eb721"
     ]
    },
    "id": "ZlhfREkkyhD6",
    "outputId": "666aae55-9f6b-4833-8f1f-5bcf628d00d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstacey\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.10<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">earthy-firefly-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/stacey/custom_pr_curve\" target=\"_blank\">https://wandb.ai/stacey/custom_pr_curve</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/stacey/custom_pr_curve/runs/mflczw0i\" target=\"_blank\">https://wandb.ai/stacey/custom_pr_curve/runs/mflczw0i</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20201112_183203-mflczw0i</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 1s 0us/step\n",
      "3/3 [==============================] - 19s 6s/step - loss: 7.1346 - accuracy: 0.1042 - val_loss: 6.4560 - val_accuracy: 0.1208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 164<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f402c6403630417388a23b752072183c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 100.14MB of 100.14MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.9999484…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/content/wandb/run-20201112_183203-mflczw0i/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/content/wandb/run-20201112_183203-mflczw0i/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>7.13461</td></tr><tr><td>accuracy</td><td>0.10417</td></tr><tr><td>val_loss</td><td>6.45605</td></tr><tr><td>val_accuracy</td><td>0.12083</td></tr><tr><td>_step</td><td>1</td></tr><tr><td>_runtime</td><td>41</td></tr><tr><td>_timestamp</td><td>1605205964</td></tr><tr><td>best_val_loss</td><td>6.45605</td></tr><tr><td>best_epoch</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>_runtime</td><td>▁█</td></tr><tr><td>_timestamp</td><td>▁█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">earthy-firefly-6</strong>: <a href=\"https://wandb.ai/stacey/custom_pr_curve/runs/mflczw0i\" target=\"_blank\">https://wandb.ai/stacey/custom_pr_curve/runs/mflczw0i</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this cell to launch your experiment!\n",
    "# charts will show up in your run page under the heading \"Custom Charts\",\n",
    "# which you may need to click on to expand\n",
    "pretrain()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNzvAfQLL7ke44GIzrtsqmk",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Plot Precision-Recall Curves with W&B",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2b9e6c5624514b04ad75d6a7563eb721": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb2de95870b4ffdb3ec3a14d9235e0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b96a9dc6abf4478a83884c9672e8075": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd80cdc597ad4c8ca743b28f3b470c39",
      "placeholder": "​",
      "style": "IPY_MODEL_8788e67cc403481dbbdf5303877f4b6b",
      "value": " 100.16MB of 100.16MB uploaded (0.00MB deduped)\r"
     }
    },
    "8788e67cc403481dbbdf5303877f4b6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89b63a2f8c894190b1d938940eba9342": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92917c9a955946d3be240b4fac968c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b9e6c5624514b04ad75d6a7563eb721",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2eb2de95870b4ffdb3ec3a14d9235e0e",
      "value": 1
     }
    },
    "dd80cdc597ad4c8ca743b28f3b470c39": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f402c6403630417388a23b752072183c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b96a9dc6abf4478a83884c9672e8075",
       "IPY_MODEL_92917c9a955946d3be240b4fac968c31"
      ],
      "layout": "IPY_MODEL_89b63a2f8c894190b1d938940eba9342"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
